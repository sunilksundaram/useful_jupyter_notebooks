{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recursive Directory Archiver with Progress Tracking\n",
    "\n",
    "This notebook creates a tar.gz archive of all files and folders starting from a specified root directory.\n",
    "\n",
    "## Installation Requirements\n",
    "\n",
    "Make sure you have tqdm installed:\n",
    "\n",
    "```bash\n",
    "pip install tqdm\n",
    "```\n",
    "\n",
    "## Features:\n",
    "- Recursively traverses all subdirectories\n",
    "- Creates compressed tar.gz archive\n",
    "- Handles file permissions and metadata\n",
    "- Beautiful progress bar with tqdm\n",
    "- Tracks omitted files and their sizes\n",
    "- Error handling for inaccessible files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install tqdm if not already installed\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "from pathlib import Path\n",
    "import time\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_size(size_bytes):\n",
    "    \"\"\"\n",
    "    Convert bytes to human readable format\n",
    "    \"\"\"\n",
    "    if size_bytes == 0:\n",
    "        return \"0 B\"\n",
    "    \n",
    "    size_names = [\"B\", \"KB\", \"MB\", \"GB\", \"TB\"]\n",
    "    i = 0\n",
    "    while size_bytes >= 1024.0 and i < len(size_names) - 1:\n",
    "        size_bytes /= 1024.0\n",
    "        i += 1\n",
    "    \n",
    "    return f\"{size_bytes:.2f} {size_names[i]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_recursive_archive(root_path, output_path, exclude_patterns=None):\n",
    "    \"\"\"\n",
    "    Create a tar.gz archive of all files and folders recursively with detailed tracking\n",
    "    \n",
    "    Args:\n",
    "        root_path (str): Root directory to archive\n",
    "        output_path (str): Output tar.gz file path\n",
    "        exclude_patterns (list): List of patterns to exclude (optional)\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if successful, False otherwise\n",
    "    \"\"\"\n",
    "    \n",
    "    if exclude_patterns is None:\n",
    "        exclude_patterns = []\n",
    "    \n",
    "    # Validate input path\n",
    "    if not os.path.exists(root_path):\n",
    "        print(f\"Error: Root path '{root_path}' does not exist.\")\n",
    "        return False\n",
    "    \n",
    "    # Get absolute paths\n",
    "    root_path = os.path.abspath(root_path)\n",
    "    output_path = os.path.abspath(output_path)\n",
    "    \n",
    "    print(f\"Starting archive creation...\")\n",
    "    print(f\"Source: {root_path}\")\n",
    "    print(f\"Output: {output_path}\")\n",
    "    print(f\"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    if exclude_patterns:\n",
    "        print(f\"Excluding patterns: {exclude_patterns}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    try:\n",
    "        # Statistics tracking\n",
    "        stats = {\n",
    "            'total_files': 0,\n",
    "            'total_dirs': 0,\n",
    "            'total_size': 0,\n",
    "            'omitted_files': 0,\n",
    "            'omitted_dirs': 0,\n",
    "            'omitted_size': 0,\n",
    "            'errors': []\n",
    "        }\n",
    "        \n",
    "        # First pass: scan and categorize all items\n",
    "        print(\"Scanning directory structure...\")\n",
    "        items_to_archive = []\n",
    "        \n",
    "        for root, dirs, files in os.walk(root_path):\n",
    "            # Process directories\n",
    "            dirs_to_keep = []\n",
    "            for dir_name in dirs:\n",
    "                stats['total_dirs'] += 1\n",
    "                if any(pattern in dir_name for pattern in exclude_patterns):\n",
    "                    stats['omitted_dirs'] += 1\n",
    "                else:\n",
    "                    dirs_to_keep.append(dir_name)\n",
    "                    dir_path = os.path.join(root, dir_name)\n",
    "                    items_to_archive.append(('dir', dir_path, dir_name))\n",
    "            \n",
    "            # Update dirs list to prevent walking into excluded directories\n",
    "            dirs[:] = dirs_to_keep\n",
    "            \n",
    "            # Process files\n",
    "            for file_name in files:\n",
    "                file_path = os.path.join(root, file_name)\n",
    "                stats['total_files'] += 1\n",
    "                \n",
    "                # Get file size\n",
    "                try:\n",
    "                    file_size = os.path.getsize(file_path)\n",
    "                    stats['total_size'] += file_size\n",
    "                except (OSError, IOError):\n",
    "                    file_size = 0\n",
    "                \n",
    "                # Check if file should be excluded\n",
    "                if any(pattern in file_name for pattern in exclude_patterns):\n",
    "                    stats['omitted_files'] += 1\n",
    "                    stats['omitted_size'] += file_size\n",
    "                else:\n",
    "                    items_to_archive.append(('file', file_path, file_name))\n",
    "        \n",
    "        # Display scan results\n",
    "        print(f\"Scan completed:\")\n",
    "        print(f\"  Total items found: {stats['total_files'] + stats['total_dirs']} (Files: {stats['total_files']}, Dirs: {stats['total_dirs']})\")\n",
    "        print(f\"  Total size: {format_size(stats['total_size'])}\")\n",
    "        print(f\"  Items to archive: {len(items_to_archive)}\")\n",
    "        \n",
    "        if stats['omitted_files'] > 0 or stats['omitted_dirs'] > 0:\n",
    "            print(f\"  Items excluded: {stats['omitted_files'] + stats['omitted_dirs']} (Files: {stats['omitted_files']}, Dirs: {stats['omitted_dirs']})\")\n",
    "            print(f\"  Excluded size: {format_size(stats['omitted_size'])}\")\n",
    "        \n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        # Second pass: create archive with progress bar\n",
    "        with tarfile.open(output_path, 'w:gz') as tar:\n",
    "            # Use tqdm for progress tracking\n",
    "            with tqdm(total=len(items_to_archive), \n",
    "                     desc=\"Creating archive\", \n",
    "                     unit=\"items\",\n",
    "                     bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]\") as pbar:\n",
    "                \n",
    "                for item_type, full_path, name in items_to_archive:\n",
    "                    try:\n",
    "                        # Calculate relative path for archive\n",
    "                        arcname = os.path.relpath(full_path, os.path.dirname(root_path))\n",
    "                        \n",
    "                        if item_type == 'dir':\n",
    "                            tar.add(full_path, arcname=arcname, recursive=False)\n",
    "                            pbar.set_postfix_str(f\"Dir: {name[:30]}\")\n",
    "                        else:  # file\n",
    "                            tar.add(full_path, arcname=arcname)\n",
    "                            pbar.set_postfix_str(f\"File: {name[:30]}\")\n",
    "                        \n",
    "                        pbar.update(1)\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        error_msg = f\"Error adding {item_type} {full_path}: {str(e)[:100]}\"\n",
    "                        stats['errors'].append(error_msg)\n",
    "                        tqdm.write(f\"Warning: {error_msg}\")\n",
    "                        pbar.update(1)\n",
    "        \n",
    "        # Final summary\n",
    "        archive_size = os.path.getsize(output_path)\n",
    "        compression_ratio = (1 - archive_size / max(stats['total_size'] - stats['omitted_size'], 1)) * 100\n",
    "        \n",
    "        print(\"-\" * 60)\n",
    "        print(f\"‚úÖ Archive creation completed successfully!\")\n",
    "        print(f\"\")\n",
    "        print(f\"üìä Summary:\")\n",
    "        print(f\"  Items processed: {len(items_to_archive)}\")\n",
    "        print(f\"  Items excluded: {stats['omitted_files'] + stats['omitted_dirs']}\")\n",
    "        print(f\"  Archive size: {format_size(archive_size)}\")\n",
    "        print(f\"  Original size: {format_size(stats['total_size'] - stats['omitted_size'])}\")\n",
    "        print(f\"  Compression ratio: {compression_ratio:.1f}%\")\n",
    "        print(f\"  Space saved by exclusions: {format_size(stats['omitted_size'])}\")\n",
    "        print(f\"  Errors encountered: {len(stats['errors'])}\")\n",
    "        \n",
    "        if stats['errors']:\n",
    "            print(f\"\\n‚ö†Ô∏è  Error details:\")\n",
    "            for i, error in enumerate(stats['errors'][:5]):\n",
    "                print(f\"  {i+1}. {error}\")\n",
    "            if len(stats['errors']) > 5:\n",
    "                print(f\"  ... and {len(stats['errors']) - 5} more errors\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Critical error during archive creation: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set your parameters here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "ROOT_DIRECTORY = \"/path/to/your/root/directory\"  # Change this to your target directory\n",
    "OUTPUT_ARCHIVE = \"archive_backup.tar.gz\"        # Output file name\n",
    "\n",
    "# Optional: Files/directories to exclude (partial matches)\n",
    "EXCLUDE_PATTERNS = [\n",
    "    \".git\",\n",
    "    \"__pycache__\",\n",
    "    \".pyc\",\n",
    "    \".DS_Store\",\n",
    "    \"node_modules\",\n",
    "    \".tmp\",\n",
    "    \".cache\",\n",
    "    \".log\"\n",
    "]\n",
    "\n",
    "print(f\"üìã Configuration:\")\n",
    "print(f\"  Root Directory: {ROOT_DIRECTORY}\")\n",
    "print(f\"  Output Archive: {OUTPUT_ARCHIVE}\")\n",
    "print(f\"  Exclude Patterns: {EXCLUDE_PATTERNS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute Archive Creation\n",
    "\n",
    "Run the cell below to start the archiving process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the archive creation\n",
    "start_time = time.time()\n",
    "\n",
    "success = create_recursive_archive(\n",
    "    root_path=ROOT_DIRECTORY,\n",
    "    output_path=OUTPUT_ARCHIVE,\n",
    "    exclude_patterns=EXCLUDE_PATTERNS\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "\n",
    "print(f\"\\n‚è±Ô∏è  Total execution time: {duration:.2f} seconds\")\n",
    "\n",
    "if success:\n",
    "    print(f\"üéâ Archive '{OUTPUT_ARCHIVE}' created successfully!\")\n",
    "else:\n",
    "    print(f\"üí• Archive creation failed. Check the error messages above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Archive (Optional)\n",
    "\n",
    "Run this cell to verify the created archive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_archive(archive_path):\n",
    "    \"\"\"\n",
    "    Verify the integrity of the created archive\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with tarfile.open(archive_path, 'r:gz') as tar:\n",
    "            members = tar.getmembers()\n",
    "            \n",
    "            files_count = len([m for m in members if m.isfile()])\n",
    "            dirs_count = len([m for m in members if m.isdir()])\n",
    "            \n",
    "            print(f\"üîç Archive verification successful!\")\n",
    "            print(f\"  Total entries: {len(members)}\")\n",
    "            print(f\"  Files: {files_count}\")\n",
    "            print(f\"  Directories: {dirs_count}\")\n",
    "            print(f\"  Archive size: {format_size(os.path.getsize(archive_path))}\")\n",
    "            \n",
    "            # Show first few entries\n",
    "            print(f\"\\nüìÅ First 10 entries:\")\n",
    "            for i, member in enumerate(members[:10]):\n",
    "                file_type = \"üìÅ\" if member.isdir() else \"üìÑ\"\n",
    "                size_info = f\" ({format_size(member.size)})\" if member.isfile() else \"\"\n",
    "                print(f\"  {file_type} {member.name}{size_info}\")\n",
    "            \n",
    "            if len(members) > 10:\n",
    "                print(f\"  ... and {len(members) - 10} more entries\")\n",
    "                \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Archive verification failed: {e}\")\n",
    "        return False\n",
    "\n",
    "# Verify the archive\n",
    "if os.path.exists(OUTPUT_ARCHIVE):\n",
    "    verify_archive(OUTPUT_ARCHIVE)\n",
    "else:\n",
    "    print(f\"‚ùå Archive file '{OUTPUT_ARCHIVE}' not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage Instructions\n",
    "\n",
    "1. **Install Dependencies**: Run the first cell to install tqdm if needed\n",
    "2. **Update Configuration**: Modify the `ROOT_DIRECTORY` variable to point to your target directory\n",
    "3. **Set Output Path**: Change `OUTPUT_ARCHIVE` to your desired output file name/path\n",
    "4. **Configure Exclusions**: Modify `EXCLUDE_PATTERNS` to exclude unwanted files/directories\n",
    "5. **Run Archive Creation**: Execute the main archiving cell\n",
    "6. **Verify Results**: Optionally run the verification cell to check the archive\n",
    "\n",
    "## Output Features\n",
    "\n",
    "The script now provides comprehensive reporting:\n",
    "\n",
    "- **Real-time progress bar** with tqdm showing current file being processed\n",
    "- **Detailed scan results** showing total files found vs. items to archive\n",
    "- **Exclusion statistics** with counts and sizes of omitted files\n",
    "- **Compression metrics** showing space savings\n",
    "- **Error tracking** with detailed error messages\n",
    "- **Archive verification** to ensure integrity\n",
    "\n",
    "## Notes\n",
    "\n",
    "- The script preserves file permissions and timestamps\n",
    "- Large directories may take significant time to process\n",
    "- The script handles errors gracefully and continues processing\n",
    "- Memory usage is optimized by streaming files to the archive\n",
    "- Progress bar shows current item being processed\n",
    "- Detailed statistics help you understand what was archived vs excluded"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
